{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage.io import imsave, imread\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50272, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This csv loads the info that will become the masks which is in run-length encoding\n",
    "train_df = pd.read_csv('~/Data/Metis/Steel/train.csv')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12568\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/robjohns/Data/Metis/Steel/train_images/\"\n",
    "train_data_path = os.path.join(data_path)\n",
    "images = os.listdir(train_data_path)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_and_mask(start_idx):\n",
    "    #in data set, each images has 4 rows, this grabs all 4 and makes sure image name matches\n",
    "    \n",
    "    col = start_idx\n",
    "    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n",
    "    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n",
    "        raise ValueError\n",
    "    \n",
    "    # This takes the 4 values of tagged pixels for each of the 4 defect tags \n",
    "    #for the current image\n",
    "    labels = train_df.iloc[col:col+4, 1]\n",
    "    \n",
    "    #makes an empty mask that is 256x1600 pixels with 4 layers for each pixel\n",
    "    mask = np.zeros((256, 1600, 4), dtype=np.uint8)\n",
    "\n",
    "    \n",
    "    #\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        \n",
    "# 4 times, once for each layer, the mask label is processed\n",
    "# the output will leave all 0's for the mask we made above if there is no code\n",
    "# or it will be converted to changing the mask on that layer\n",
    "        \n",
    "        if label is not np.nan:\n",
    "            mask_label = np.zeros(1600*256, dtype=np.uint8)\n",
    "            label = label.split(\" \")\n",
    "\n",
    "#makes a list out of non-zero labels, alternating between positions and lengths\n",
    "            \n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            \n",
    "#makes lists of positions and lengths by iterating every other, \n",
    "#and forces them to become int          \n",
    "            \n",
    "            for pos, le in zip(positions, length):\n",
    "                mask_label[pos-1:pos+le-1] = 1\n",
    "            mask[:, :, idx] = mask_label.reshape(256, 1600, order='F')\n",
    "# the positions called in label are turned to 1 in the mask for this layer\n",
    "    \n",
    "    return img_names[0], mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a full table of 4 masks per image with dims [numpix,vertpix,horpix,masks(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Masks\n",
    "\n",
    "yname=[]\n",
    "y=[]\n",
    "for idx in range(0,128,4):\n",
    "    pix,masks=name_and_mask(idx)\n",
    "    indy=int(idx/4)\n",
    "    y.append(masks.astype(np.float32))\n",
    "    yname.append(pix)\n",
    "y=np.stack(y, axis=0)  \n",
    "y_train=y\n",
    "\n",
    "\n",
    "y_test=[]\n",
    "for idx in range(0,128,4):\n",
    "    pix,masks=name_and_mask(idx)\n",
    "    indy=int(idx/4)\n",
    "    y_test.append(masks.astype(np.float32))\n",
    "y_test=np.stack(y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process image files into numpy arrays \n",
    "x=[]\n",
    "for idx in range(0,128,4):    \n",
    "    name, mask = name_and_mask(idx)\n",
    "    abs_path = \"/Users/robjohns/Data/Metis/Steel/train_images/\"\n",
    "    filename=abs_path+name\n",
    "    impath = Path(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    x.append(img.astype(np.float32))\n",
    "x=np.stack(x, axis=0)   \n",
    "x_train=x\n",
    "x_train=x_train/255\n",
    "\n",
    "x_test=[]\n",
    "for idx in range(0,128,4):    \n",
    "    name, mask = name_and_mask(idx)\n",
    "    abs_path = \"/Users/robjohns/Data/Metis/Steel/train_images/\"\n",
    "    filename=abs_path+name\n",
    "    impath = Path(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    x_test.append(img.astype(np.float32))\n",
    "x_test=np.stack(x_test, axis=0)\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-189e6887f2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im_idx_list = []\n",
    "im_idx_list_onlydf = []\n",
    "im_idx_list_nodf = []\n",
    "\n",
    "\n",
    "for col in range(0, len(train_df), 4):\n",
    "    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n",
    "    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n",
    "        raise ValueError\n",
    "        \n",
    "    \n",
    "    \n",
    "    labels = train_df.iloc[col:col+4, 1]\n",
    "    if labels.isna().all():\n",
    "        im_idx_list_nodf.append(col)\n",
    "        im_idx_list.append(col)\n",
    "        \n",
    "        \n",
    "    elif (labels.isna() == [False, True, True, True]).all():\n",
    "        im_idx_list.append(col)\n",
    "        im_idx_list_onlydf.append(col)\n",
    "        \n",
    "    elif (labels.isna() == [True, False, True, True]).all():\n",
    "        im_idx_list.append(col)\n",
    "        im_idx_list_onlydf.append(col)\n",
    "        \n",
    "    elif (labels.isna() == [True, True, False, True]).all():\n",
    "        im_idx_list.append(col)\n",
    "        im_idx_list_onlydf.append(col)\n",
    "        \n",
    "    elif (labels.isna() == [True, True, True, False]).all():\n",
    "        im_idx_list.append(col)\n",
    "        im_idx_list_onlydf.append(col)\n",
    "        \n",
    "    else:\n",
    "        im_idx_list.append(col)\n",
    "        im_idx_list_onlydf.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c54edd000b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTFSCGen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"Generator class for Tensorflow Speech Competition data\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mgen_path\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpatlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mpointing\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class TFSCGen(keras.utils.Sequence):\n",
    "    \"\"\"Generator class for Tensorflow Speech Competition data\n",
    "    \n",
    "    args:\n",
    "        - gen_path (patlib.Path): a path pointing to a directory containing training examples\n",
    "            examples should be stored in format `gen_path/[class_name]/[file_name].wav`\n",
    "        - batch_size (int): size of batches to return\n",
    "        - shuffle (bool): whether or not data is to be shuffled between batches\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, gen_path=im_idx_list, batch_size = 32, shuffle=True):\n",
    "        \n",
    "        \n",
    "        self.gen_files = im_idx_list\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.gen_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the number of examples\"\"\"\n",
    "        \n",
    "        return int(np.ceil(len(self.gen_files) / float(self.batch_size)))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"shuffles data after an epoch runs (but only if self.shuffle is set)\"\"\"\n",
    "        \n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.gen_files)\n",
    "            \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"function to return the batch given the batch index\n",
    "        \n",
    "        args:\n",
    "            idx (int): this is the batch index generated by keras\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        start_idx = idx*self.batch_size\n",
    "        batch_rows = self.gen_files[start_idx:start_idx+self.batch_size]\n",
    "        \n",
    "        x=[]\n",
    "        for idx in batch_rows:    \n",
    "            name, mask = name_and_mask(idx)\n",
    "            abs_path = \"/Users/robjohns/Data/Metis/Steel/train_images/\"\n",
    "            #need to generalize this for tests\n",
    "            \n",
    "            filename=abs_path+name\n",
    "            impath = Path(filename)\n",
    "            img = cv2.imread(filename)\n",
    "            x.append(img.astype(np.float32))\n",
    "        x=np.stack(x, axis=0)   \n",
    "        x=x/255\n",
    "        \n",
    "        \n",
    "        y=[]\n",
    "        for idx in batch_rows:\n",
    "            pix,masks=name_and_mask(idx)\n",
    "            indy=int(idx/4)\n",
    "            y.append(masks.astype(np.float32))\n",
    "            yname.append(pix)\n",
    "        y=np.stack(y, axis=0)  \n",
    "        \n",
    "        \n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put TFSCGen() where x,y would be in model call\n",
    "\n",
    "# example:  conv_model.fit(TFSCGen(), validation_data=TFSCGen(tfsc_val),\n",
    "               epochs=100,\n",
    "               callbacks=[\n",
    "                   keras.callbacks.ReduceLROnPlateau(patience=3, verbose=True), \n",
    "                   keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, verbose=True)\n",
    "               ]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do test train split here, you need to send x_train, y_train, x_test, and y_test to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x),len(y),len(yname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('imgs_masks.npy', y)\n",
    "np.save('imgs.npy', x)\n",
    "np.save('imgs_names.npy', yname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50272/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet from https://github.com/jocicmarko/ultrasound-nerve-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    inputs = Input((256, 1600, 3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(48, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(48, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(72, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(72, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(108, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(108, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(162, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(162, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(108, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(108, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(72, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(72, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(48, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(48, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(4, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 1600, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 256, 1600, 32 896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 256, 1600, 32 9248        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 128, 800, 32) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 800, 48) 13872       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 128, 800, 48) 20784       conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 64, 400, 48)  0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 400, 72)  31176       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 64, 400, 72)  46728       conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 200, 72)  0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 200, 108) 70092       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 200, 108) 105084      conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 16, 100, 108) 0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 100, 162) 157626      max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 100, 162) 236358      conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 32, 200, 256) 166144      conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 200, 364) 0           conv2d_transpose_8[0][0]         \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 200, 108) 353916      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 200, 108) 105084      conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 64, 400, 128) 55424       conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 64, 400, 200) 0           conv2d_transpose_9[0][0]         \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 64, 400, 72)  129672      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 64, 400, 72)  46728       conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 128, 800, 64) 18496       conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 128, 800, 112 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 800, 48) 48432       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 128, 800, 48) 20784       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 256, 1600, 32 6176        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 256, 1600, 64 0           conv2d_transpose_11[0][0]        \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 256, 1600, 32 18464       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 256, 1600, 32 9248        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 256, 1600, 4) 132         conv2d_55[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,670,564\n",
      "Trainable params: 1,670,564\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_model = get_unet()\n",
    "\n",
    "unet_model.summary()\n",
    "#check dimensions match expected output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict():\n",
    "\n",
    "    #'Loading and preprocessing train data\n",
    "    \n",
    "   \n",
    "    imgs_train, imgs_mask_train = x_train, y_train\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #imgs_train = imgs_train/255\n",
    "    \n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    #imgs_train -= mean\n",
    "    #imgs_train /= std\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    #Creating and compiling model\n",
    "    \n",
    "    \n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    \n",
    "    # Fitting model\n",
    "    \n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=32, epochs=2, verbose=1, shuffle=True,\n",
    "              validation_split=0,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    \n",
    "    #Loading and preprocessing test data\n",
    "    \n",
    "    imgs_test, imgs_id_test = x_test, y_test\n",
    "    \n",
    "\n",
    "    imgs_test # /=  255.\n",
    "    #imgs_test -= mean\n",
    "    #imgs_test /= std\n",
    "\n",
    "    \n",
    "    # Loading saved weights.\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    \n",
    "    #Predicting masks on test data\n",
    "    \n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    \n",
    "    #convert masks to a table of run length encoding\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "32/32 [==============================] - 185s 6s/sample - loss: -0.0088 - dice_coef: 0.0088\n",
      "Epoch 2/2\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "32/32 [==============================] - 157s 5s/sample - loss: -0.0098 - dice_coef: 0.0098\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8e9ac8e2e77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-ffee1eedcf66>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Loading saved weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    179\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1363\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   1364\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
